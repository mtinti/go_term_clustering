{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n of workers: 4\n",
      "4\n",
      "{   0: {   'completed': 15, 'queue': 0, 'tasks': 0},\n",
      "    1: {   'completed': 15, 'queue': 0, 'tasks': 0},\n",
      "    2: {   'completed': 15, 'queue': 0, 'tasks': 0},\n",
      "    3: {   'completed': 15, 'queue': 0, 'tasks': 0},\n",
      "    'unassigned': 0}\n"
     ]
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "rc = Client()\n",
    "data_path = os.path.abspath(\"data\")\n",
    "res_path = os.path.abspath(\"results\")\n",
    "random_path = os.path.abspath(\"random\")\n",
    "dview = rc.load_balanced_view()\n",
    "#dview = rc.direct_view('all')\n",
    "print 'n of workers:', len(dview)\n",
    "print len(rc)\n",
    "pp.pprint(dview.queue_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "import os\n",
    "import pandas as pd\n",
    "from string import strip\n",
    "import numpy as np\n",
    "from string import strip\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "def process(batch):\n",
    "    print 'start'\n",
    "    res = [ [str(stats.pearsonr(values_df.loc[n[0]], values_df.loc[n[1]])[0]),str(n[2]),str(n[3])] for n in batch]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  median_1     median_2     median_3\n",
      "Tb927.10.3210  688310000.0  276010000.0  215760000.0\n",
      "Tb927.5.2310           0.0          0.0          0.0\n",
      "Tb927.8.7570           0.0          0.0          0.0\n",
      "               clusters_0.0  clusters_0.06  clusters_0.09\n",
      "Tb927.10.3210          2325           2324           2323\n",
      "Tb927.5.2310           1801           1800           1800\n",
      "Tb927.8.7570           3018           3017           3016\n",
      "29319788\n"
     ]
    }
   ],
   "source": [
    "values_df = pd.DataFrame.from_csv(os.path.join(data_path,'in_df.txt'),sep='\\t')\n",
    "cluster_res = pd.DataFrame.from_csv('res_clustering.csv')\n",
    "print values_df.iloc[:3,:3]\n",
    "print cluster_res.iloc[:3,:3]\n",
    "pairs = []\n",
    "for index, cut_distance in enumerate(cluster_res.columns):\n",
    "    temp_df = pd.concat([values_df,cluster_res[cut_distance]],1)\n",
    "    n_of_clusters = cluster_res[cut_distance].value_counts()\n",
    "    n_of_clusters = n_of_clusters[n_of_clusters>=2]\n",
    "    for cluster_id in n_of_clusters.index.values:\n",
    "        genes = temp_df[temp_df[cut_distance]==cluster_id].index.values\n",
    "        temp_pairs = list(combinations(genes,2))\n",
    "        temp_pairs = [(n[0],n[1],cut_distance,cluster_id) for n in temp_pairs]\n",
    "        pairs+=temp_pairs\n",
    "print len(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293198\n"
     ]
    }
   ],
   "source": [
    "split = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]\n",
    "batches = [n for n in split(pairs, 10000)]\n",
    "print len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------send to-------------\n",
      "\n",
      "0.0169999599457\n",
      "min:  0.000299998124441\n",
      "h:  4.99996874068e-06\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rc[:].push(dict(\n",
    "    values_df=values_df       \n",
    "))\n",
    "\n",
    "start_time = time.time()\n",
    "tasks = []\n",
    "for batch in batches[0:4]:\n",
    "    ar = dview.apply_async(process, batch)\n",
    "    tasks.append(ar)\n",
    "print '-------send to-------------\\n'     \n",
    "print time.time() - start_time\n",
    "print 'min: ', (time.time() - start_time)/60\n",
    "print 'h: ', (time.time() - start_time)/60/60\n",
    "print '-------------------------\\n'\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   0: {   'completed': 112, 'queue': 0, 'tasks': 1},\n",
      "    1: {   'completed': 113, 'queue': 1, 'tasks': 1},\n",
      "    2: {   'completed': 113, 'queue': 1, 'tasks': 1},\n",
      "    3: {   'completed': 113, 'queue': 0, 'tasks': 1},\n",
      "    'unassigned': 0}\n",
      "4\n",
      "['0.999387723211', 'clusters_0.06', '54']\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(dview.queue_status())\n",
    "print len(tasks)\n",
    "print tasks[0].get()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tasks = [n.get() for  n in tasks]\n",
    "file_res  = open('pearson_res.txt','w')\n",
    "for batch in tasks:\n",
    "    for item in batch:\n",
    "       file_res.write('\\t'.join(item)+'\\n') \n",
    "file_res.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0              1     2\n",
      "0  0.999388  clusters_0.06    54\n",
      "1  0.998297  clusters_0.09  2270\n",
      "2  0.999388  clusters_0.09    54\n",
      "3  0.999388   clusters_0.1    54\n",
      "4  0.997761   clusters_0.1  1719\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('perason_res.txt',sep='\\t',header =None)\n",
    "df.columns = ['person','cut_distance','cluster_id']\n",
    "df['cut_distance']=[float(n.split('_')[1]) for n in df['cut_distance']]\n",
    "df.sort_values(by='cut_distance', ascending=True, inplace=True)\n",
    "print df.head()\n",
    "combined = df.groupby('cut_distance').mean()\n",
    "del combined['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del combined['cluster_id']\n",
    "combined.to_csv('reduced_pearson.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
